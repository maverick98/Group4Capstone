PROJECT 5
Domain: Creative media
Techniques: Deep learning, NLP
Title: Image captioning using a CNN and a Transformer
Overview and Problem Statement
Automatic image captioning (tagging) is useful for organizing images with less time and
effort. Automated image captioning uses machine learning to 'read' the visual content and
generate text descriptions to explain what is shown on the picture. Image captioning can be
used to improve assistive technology and aid visually impaired people to comprehend their
environment. The captions generated as output can be read aloud to the users and help
them to interact with it better
Dataset
The Flickr 8k dataset is a benchmark collection for sentence-based image description and
search, consisting of 8,000 images that are each paired with five different captions which
provide clear descriptions of the salient entities and events. The images were chosen from
six different Flickr groups, and tend not to contain any well-known people or locations, but
were manually selected to depict a variety of scenes and situations
Dataset links:
Images:
https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip
Text Captions:
https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip
Specific Challenges:
Achieving a BLEU score of >50
References:
1. https://blog.paperspace.com/image-captioning-with-tensorflow/
2.
https://medium.com/@raman.shinde15/image-captioning-with-flickr8k-dataset-bleu-4bcba0b52926

More links.
https://towardsdatascience.com/image-captioning-with-keras-teaching-computers-to-describe-pictures-c88a46a311b8
https://www.youtube.com/watch?v=rLyF4XQLwr0
